<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" 
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head profile="http://www.w3.org/2006/03/hcard http://dublincore.org/documents/2008/08/04/dc-html/">
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />

  <title>Video Codec Testing and Quality Measurement</title>

  <style type="text/css" title="Xml2Rfc (sans serif)">
  /*<![CDATA[*/
	  a {
	  text-decoration: none;
	  }
	  a.smpl {
	  color: black;
	  }
	  a:hover {
	  text-decoration: underline;
	  }
	  a:active {
	  text-decoration: underline;
	  }
	  address {
	  margin-top: 1em;
	  margin-left: 2em;
	  font-style: normal;
	  }
	  body {
	  color: black;
	  font-family: verdana, helvetica, arial, sans-serif;
	  font-size: 10pt;
	  max-width: 55em;
	  
	  }
	  cite {
	  font-style: normal;
	  }
	  dd {
	  margin-right: 2em;
	  }
	  dl {
	  margin-left: 2em;
	  }
	
	  ul.empty {
	  list-style-type: none;
	  }
	  ul.empty li {
	  margin-top: .5em;
	  }
	  dl p {
	  margin-left: 0em;
	  }
	  dt {
	  margin-top: .5em;
	  }
	  h1 {
	  font-size: 14pt;
	  line-height: 21pt;
	  page-break-after: avoid;
	  }
	  h1.np {
	  page-break-before: always;
	  }
	  h1 a {
	  color: #333333;
	  }
	  h2 {
	  font-size: 12pt;
	  line-height: 15pt;
	  page-break-after: avoid;
	  }
	  h3, h4, h5, h6 {
	  font-size: 10pt;
	  page-break-after: avoid;
	  }
	  h2 a, h3 a, h4 a, h5 a, h6 a {
	  color: black;
	  }
	  img {
	  margin-left: 3em;
	  }
	  li {
	  margin-left: 2em;
	  margin-right: 2em;
	  }
	  ol {
	  margin-left: 2em;
	  margin-right: 2em;
	  }
	  ol p {
	  margin-left: 0em;
	  }
	  p {
	  margin-left: 2em;
	  margin-right: 2em;
	  }
	  pre {
	  margin-left: 3em;
	  background-color: lightyellow;
	  padding: .25em;
	  }
	  pre.text2 {
	  border-style: dotted;
	  border-width: 1px;
	  background-color: #f0f0f0;
	  width: 69em;
	  }
	  pre.inline {
	  background-color: white;
	  padding: 0em;
	  }
	  pre.text {
	  border-style: dotted;
	  border-width: 1px;
	  background-color: #f8f8f8;
	  width: 69em;
	  }
	  pre.drawing {
	  border-style: solid;
	  border-width: 1px;
	  background-color: #f8f8f8;
	  padding: 2em;
	  }
	  table {
	  margin-left: 2em;
	  }
	  table.tt {
	  vertical-align: top;
	  }
	  table.full {
	  border-style: outset;
	  border-width: 1px;
	  }
	  table.headers {
	  border-style: outset;
	  border-width: 1px;
	  }
	  table.tt td {
	  vertical-align: top;
	  }
	  table.full td {
	  border-style: inset;
	  border-width: 1px;
	  }
	  table.tt th {
	  vertical-align: top;
	  }
	  table.full th {
	  border-style: inset;
	  border-width: 1px;
	  }
	  table.headers th {
	  border-style: none none inset none;
	  border-width: 1px;
	  }
	  table.left {
	  margin-right: auto;
	  }
	  table.right {
	  margin-left: auto;
	  }
	  table.center {
	  margin-left: auto;
	  margin-right: auto;
	  }
	  caption {
	  caption-side: bottom;
	  font-weight: bold;
	  font-size: 9pt;
	  margin-top: .5em;
	  }
	
	  table.header {
	  border-spacing: 1px;
	  width: 95%;
	  font-size: 10pt;
	  color: white;
	  }
	  td.top {
	  vertical-align: top;
	  }
	  td.topnowrap {
	  vertical-align: top;
	  white-space: nowrap; 
	  }
	  table.header td {
	  background-color: gray;
	  width: 50%;
	  }
	  table.header a {
	  color: white;
	  }
	  td.reference {
	  vertical-align: top;
	  white-space: nowrap;
	  padding-right: 1em;
	  }
	  thead {
	  display:table-header-group;
	  }
	  ul.toc, ul.toc ul {
	  list-style: none;
	  margin-left: 1.5em;
	  margin-right: 0em;
	  padding-left: 0em;
	  }
	  ul.toc li {
	  line-height: 150%;
	  font-weight: bold;
	  font-size: 10pt;
	  margin-left: 0em;
	  margin-right: 0em;
	  }
	  ul.toc li li {
	  line-height: normal;
	  font-weight: normal;
	  font-size: 9pt;
	  margin-left: 0em;
	  margin-right: 0em;
	  }
	  li.excluded {
	  font-size: 0pt;
	  }
	  ul p {
	  margin-left: 0em;
	  }
	
	  .comment {
	  background-color: yellow;
	  }
	  .center {
	  text-align: center;
	  }
	  .error {
	  color: red;
	  font-style: italic;
	  font-weight: bold;
	  }
	  .figure {
	  font-weight: bold;
	  text-align: center;
	  font-size: 9pt;
	  }
	  .filename {
	  color: #333333;
	  font-weight: bold;
	  font-size: 12pt;
	  line-height: 21pt;
	  text-align: center;
	  }
	  .fn {
	  font-weight: bold;
	  }
	  .hidden {
	  display: none;
	  }
	  .left {
	  text-align: left;
	  }
	  .right {
	  text-align: right;
	  }
	  .title {
	  color: #990000;
	  font-size: 18pt;
	  line-height: 18pt;
	  font-weight: bold;
	  text-align: center;
	  margin-top: 36pt;
	  }
	  .vcardline {
	  display: block;
	  }
	  .warning {
	  font-size: 14pt;
	  background-color: yellow;
	  }
	
	
	  @media print {
	  .noprint {
		display: none;
	  }
	
	  a {
		color: black;
		text-decoration: none;
	  }
	
	  table.header {
		width: 90%;
	  }
	
	  td.header {
		width: 50%;
		color: black;
		background-color: white;
		vertical-align: top;
		font-size: 12pt;
	  }
	
	  ul.toc a::after {
		content: leader('.') target-counter(attr(href), page);
	  }
	
	  ul.ind li li a {
		content: target-counter(attr(href), page);
	  }
	
	  .print2col {
		column-count: 2;
		-moz-column-count: 2;
		column-fill: auto;
	  }
	  }
	
	  @page {
	  @top-left {
		   content: "Internet-Draft"; 
	  } 
	  @top-right {
		   content: "December 2010"; 
	  } 
	  @top-center {
		   content: "Abbreviated Title";3
	  } 
	  @bottom-left {
		   content: "Doe"; 
	  } 
	  @bottom-center {
		   content: "Expires June 2011"; 
	  } 
	  @bottom-right {
		   content: "[Page " counter(page) "]"; 
	  } 
	  }
	
	  @page:first { 
		@top-left {
		  content: normal;
		}
		@top-right {
		  content: normal;
		}
		@top-center {
		  content: normal;
		}
	  }
  /*]]>*/
  </style>
  <style type="text/css">
@viewport {
  zoom: 1.0;
  width: extend-to-zoom;
}

@-ms-viewport {
  width: extend-to-zoom;
  zoom: 1.0;
}

body {
  font: 11pt cambria, helvetica, arial, sans-serif;
  font-size-adjust: 0.5;
  line-height: 130%;
  margin: 1em auto;
  max-width: 700px;
}

.title, .filename, h1, h2, h3, h4 {
  font-family: candara, helvetica, arial, sans-serif;
  font-size-adjust: 0.5;
}
.title { font-size: 150%; }
h1 { font-size: 130%; }
h2 { font-size: 120%; }
h3, h4 { font-size: 110%; }

table {
  margin-left: 0em;
}
table.header {
  width: 100%;
}

table.header td {
  background-color: inherit;
  color: black;
}

samp, tt, code, pre {
  font: 11pt consolas, monospace;
  font-size-adjust: none;
}

pre.text, pre.text2 {
  width: 90%;
}

dt {
  float: left; clear: left;
  margin: 0.5em 0.5em 0 0;
}
dt:first-child {
  margin-top: 0;
}
dd {
  margin: 0.5em 0 0 2em;
}
dd p, dd ul {
  margin-top: 0; margin-bottom: 0;
}
dd *+p {
  margin-top: 0.5em;
}

ol, ul {
  padding: 0;
  margin: 0.5em 0 0.5em 2em;
}
ul.toc, ul.toc ul {
  margin: 0 0 0 1.5em;
}
ul.toc a:first-child {
  display: inline-block;
  min-width: 1.2em;
}
  </style>

  <link href="#rfc.toc" rel="Contents"/>
<link href="#rfc.section.1" rel="Chapter" title="1 Introduction"/>
<link href="#rfc.section.2" rel="Chapter" title="2 Subjective quality tests"/>
<link href="#rfc.section.2.1" rel="Chapter" title="2.1 Still Image Pair Comparison"/>
<link href="#rfc.section.2.2" rel="Chapter" title="2.2 Video Pair Comparison"/>
<link href="#rfc.section.2.3" rel="Chapter" title="2.3 Subjective viewing test"/>
<link href="#rfc.section.3" rel="Chapter" title="3 Objective Metrics"/>
<link href="#rfc.section.3.1" rel="Chapter" title="3.1 Overall PSNR"/>
<link href="#rfc.section.3.2" rel="Chapter" title="3.2 Frame-averaged PSNR"/>
<link href="#rfc.section.3.3" rel="Chapter" title="3.3 PSNR-HVS-M"/>
<link href="#rfc.section.3.4" rel="Chapter" title="3.4 SSIM"/>
<link href="#rfc.section.3.5" rel="Chapter" title="3.5 Multi-Scale SSIM"/>
<link href="#rfc.section.3.6" rel="Chapter" title="3.6 Fast Multi-Scale SSIM"/>
<link href="#rfc.section.3.7" rel="Chapter" title="3.7 CIEDE2000"/>
<link href="#rfc.section.3.8" rel="Chapter" title="3.8 VMAF"/>
<link href="#rfc.section.4" rel="Chapter" title="4 Comparing and Interpreting Results"/>
<link href="#rfc.section.4.1" rel="Chapter" title="4.1 Graphing"/>
<link href="#rfc.section.4.2" rel="Chapter" title="4.2 Bjontegaard"/>
<link href="#rfc.section.4.3" rel="Chapter" title="4.3 Ranges"/>
<link href="#rfc.section.5" rel="Chapter" title="5 Test Sequences"/>
<link href="#rfc.section.5.1" rel="Chapter" title="5.1 Sources"/>
<link href="#rfc.section.5.2" rel="Chapter" title="5.2 Test Sets"/>
<link href="#rfc.section.5.3" rel="Chapter" title="5.3 Operating Points"/>
<link href="#rfc.section.5.3.1" rel="Chapter" title="5.3.1 Common settings"/>
<link href="#rfc.section.5.3.2" rel="Chapter" title="5.3.2 High Latency CQP"/>
<link href="#rfc.section.5.3.3" rel="Chapter" title="5.3.3 Low Latency CQP"/>
<link href="#rfc.section.5.3.4" rel="Chapter" title="5.3.4 Unconstrained High Latency"/>
<link href="#rfc.section.5.3.5" rel="Chapter" title="5.3.5 Unconstrained Low Latency"/>
<link href="#rfc.section.6" rel="Chapter" title="6 Automation"/>
<link href="#rfc.section.6.1" rel="Chapter" title="6.1 Regression tests"/>
<link href="#rfc.section.6.2" rel="Chapter" title="6.2 Objective performance tests"/>
<link href="#rfc.section.6.3" rel="Chapter" title="6.3 Periodic tests"/>
<link href="#rfc.references" rel="Chapter" title="7 Informative References"/>
<link href="#rfc.authors" rel="Chapter"/>


  <meta name="generator" content="xml2rfc version 2.4.2 - http://tools.ietf.org/tools/xml2rfc" />
  <link rel="schema.dct" href="http://purl.org/dc/terms/" />

  <meta name="dct.creator" content="Daede, T., Norkin, A., and I. Brailovskiy" />
  <meta name="dct.identifier" content="urn:ietf:id:draft-ietf-netvc-testing-latest" />
  <meta name="dct.issued" scheme="ISO8601" content="2016-4-15" />
  <meta name="dct.abstract" content="This document describes guidelines and procedures for evaluating a video codec. This covers subjective and objective tests, test conditions, and materials used for the test." />
  <meta name="description" content="This document describes guidelines and procedures for evaluating a video codec. This covers subjective and objective tests, test conditions, and materials used for the test." />

</head>

<body>

  <table class="header">
    <tbody>
    
    	<tr>
  <td class="left">Network Working Group</td>
  <td class="right">T. Daede</td>
</tr>
<tr>
  <td class="left">Internet-Draft</td>
  <td class="right">Mozilla</td>
</tr>
<tr>
  <td class="left">Intended status: Informational</td>
  <td class="right">A. Norkin</td>
</tr>
<tr>
  <td class="left">Expires: October 17, 2016</td>
  <td class="right">Netflix</td>
</tr>
<tr>
  <td class="left"></td>
  <td class="right">I. Brailovskiy</td>
</tr>
<tr>
  <td class="left"></td>
  <td class="right">Amazon Lab126</td>
</tr>
<tr>
  <td class="left"></td>
  <td class="right">April 15, 2016</td>
</tr>

    	
    </tbody>
  </table>

  <p class="title">Video Codec Testing and Quality Measurement<br />
  <span class="filename">draft-ietf-netvc-testing-latest</span></p>
  
  <h1 id="rfc.abstract">
  <a href="#rfc.abstract">Abstract</a>
</h1>
<p>This document describes guidelines and procedures for evaluating a video codec. This covers subjective and objective tests, test conditions, and materials used for the test.</p>
<h1 id="rfc.status">
  <a href="#rfc.status">Status of This Memo</a>
</h1>
<p>This Internet-Draft is submitted in full conformance with the provisions of BCP 78 and BCP 79.</p>
<p>Internet-Drafts are working documents of the Internet Engineering Task Force (IETF).  Note that other groups may also distribute working documents as Internet-Drafts.  The list of current Internet-Drafts is at http://datatracker.ietf.org/drafts/current/.</p>
<p>Internet-Drafts are draft documents valid for a maximum of six months and may be updated, replaced, or obsoleted by other documents at any time.  It is inappropriate to use Internet-Drafts as reference material or to cite them other than as "work in progress."</p>
<p>This Internet-Draft will expire on October 17, 2016.</p>
<h1 id="rfc.copyrightnotice">
  <a href="#rfc.copyrightnotice">Copyright Notice</a>
</h1>
<p>Copyright (c) 2016 IETF Trust and the persons identified as the document authors.  All rights reserved.</p>
<p>This document is subject to BCP 78 and the IETF Trust's Legal Provisions Relating to IETF Documents (http://trustee.ietf.org/license-info) in effect on the date of publication of this document.  Please review these documents carefully, as they describe your rights and restrictions with respect to this document.  Code Components extracted from this document must include Simplified BSD License text as described in Section 4.e of the Trust Legal Provisions and are provided without warranty as described in the Simplified BSD License.</p>

  
  <hr class="noprint" />
  <h1 class="np" id="rfc.toc"><a href="#rfc.toc">Table of Contents</a></h1>
  <ul class="toc">

  	<li>1.   <a href="#rfc.section.1">Introduction</a></li>
<li>2.   <a href="#rfc.section.2">Subjective quality tests</a></li>
<li>2.1.   <a href="#rfc.section.2.1">Still Image Pair Comparison</a></li>
<li>2.2.   <a href="#rfc.section.2.2">Video Pair Comparison</a></li>
<li>2.3.   <a href="#rfc.section.2.3">Subjective viewing test</a></li>
<li>3.   <a href="#rfc.section.3">Objective Metrics</a></li>
<li>3.1.   <a href="#rfc.section.3.1">Overall PSNR</a></li>
<li>3.2.   <a href="#rfc.section.3.2">Frame-averaged PSNR</a></li>
<li>3.3.   <a href="#rfc.section.3.3">PSNR-HVS-M</a></li>
<li>3.4.   <a href="#rfc.section.3.4">SSIM</a></li>
<li>3.5.   <a href="#rfc.section.3.5">Multi-Scale SSIM</a></li>
<li>3.6.   <a href="#rfc.section.3.6">Fast Multi-Scale SSIM</a></li>
<li>3.7.   <a href="#rfc.section.3.7">CIEDE2000</a></li>
<li>3.8.   <a href="#rfc.section.3.8">VMAF</a></li>
<li>4.   <a href="#rfc.section.4">Comparing and Interpreting Results</a></li>
<li>4.1.   <a href="#rfc.section.4.1">Graphing</a></li>
<li>4.2.   <a href="#rfc.section.4.2">Bjontegaard</a></li>
<li>4.3.   <a href="#rfc.section.4.3">Ranges</a></li>
<li>5.   <a href="#rfc.section.5">Test Sequences</a></li>
<li>5.1.   <a href="#rfc.section.5.1">Sources</a></li>
<li>5.2.   <a href="#rfc.section.5.2">Test Sets</a></li>
<li>5.3.   <a href="#rfc.section.5.3">Operating Points</a></li>
<li>5.3.1.   <a href="#rfc.section.5.3.1">Common settings</a></li>
<li>5.3.2.   <a href="#rfc.section.5.3.2">High Latency CQP</a></li>
<li>5.3.3.   <a href="#rfc.section.5.3.3">Low Latency CQP</a></li>
<li>5.3.4.   <a href="#rfc.section.5.3.4">Unconstrained High Latency</a></li>
<li>5.3.5.   <a href="#rfc.section.5.3.5">Unconstrained Low Latency</a></li>
<li>6.   <a href="#rfc.section.6">Automation</a></li>
<li>6.1.   <a href="#rfc.section.6.1">Regression tests</a></li>
<li>6.2.   <a href="#rfc.section.6.2">Objective performance tests</a></li>
<li>6.3.   <a href="#rfc.section.6.3">Periodic tests</a></li>
<li>7.   <a href="#rfc.references">Informative References</a></li>
<li><a href="#rfc.authors">Authors' Addresses</a></li>


  </ul>

  <h1 id="rfc.section.1"><a href="#rfc.section.1">1.</a> <a href="#introduction" id="introduction">Introduction</a></h1>
<p id="rfc.section.1.p.1">When developing a video codec, changes and additions to the codec need to be decided based on their performance tradeoffs. In addition, measurements are needed to determine when the codec has met its performance goals. This document specifies how the tests are to be carried about to ensure valid comparisons when evaluating changes under consideration. Authors of features or changes should provide the results of the appropriate test when proposing codec modifications.</p>
<h1 id="rfc.section.2"><a href="#rfc.section.2">2.</a> <a href="#subjective-quality-tests" id="subjective-quality-tests">Subjective quality tests</a></h1>
<p id="rfc.section.2.p.1">Subjective testing is the preferable method of testing video codecs.</p>
<p id="rfc.section.2.p.2">Subjective testing results take priority over objective testing results, when available. Subjective testing is recommended especially when taking advantage of psychovisual effects that may not be well represented by objective metrics, or when different objective metrics disagree.</p>
<p id="rfc.section.2.p.3">Selection of a testing methodology depends on the feature being tested and the resources available. Test methodologies are presented in order of increasing accuracy and cost.</p>
<p id="rfc.section.2.p.4">Testing relies on the resources of participants. For this reason, even if the group agrees that a particular test is important, if no one volunteers to do it, or if volunteers do not complete it in a timely fashion, then that test should be discarded.  This ensures that only important tests be done in particular, the tests that are important to participants.</p>
<h1 id="rfc.section.2.1"><a href="#rfc.section.2.1">2.1.</a> <a href="#still-image-pair-comparison" id="still-image-pair-comparison">Still Image Pair Comparison</a></h1>
<p id="rfc.section.2.1.p.1">A simple way to determine superiority of one compressed image is to visually compare two compressed images, and have the viewer judge which one has a higher quality. This is used for rapid comparisons during development - the viewer may be a developer or user, for example. Because testing is done on still images (keyframes), this is only suitable for changes with similar or no effect on other frames. For example, this test may be suitable for an intra de-ringing filter, but not for a new inter prediction mode. For this test, the two compressed images should have similar compressed file sizes, with one image being no more than 5% larger than the other. In addition, at least 5 different images should be compared.</p>
<h1 id="rfc.section.2.2"><a href="#rfc.section.2.2">2.2.</a> <a href="#video-pair-comparison" id="video-pair-comparison">Video Pair Comparison</a></h1>
<p id="rfc.section.2.2.p.1">Video comparisons are necessary when making changes with temporal effects, such as changes to inter-frame prediction. Video pair comparisons follow the same procedure as still images.</p>
<h1 id="rfc.section.2.3"><a href="#rfc.section.2.3">2.3.</a> <a href="#subjective-viewing-test" id="subjective-viewing-test">Subjective viewing test</a></h1>
<p id="rfc.section.2.3.p.1">A subjective viewing test is the preferred method of evaluating the quality. The subjective test should be performed as either consecutively showing the video sequences on one screen or on two screens located side-by-side. The testing procedure should normally follow rules described in <a href="#BT500">[BT500]</a> and be performed with non-expert test subjects. The result of the test could be (depending on the test procedure) mean opinion scores (MOS) or differential mean opinion scores (DMOS). Normally, confidence intervals are also calculated to judge whether the difference between two encodings is statistically significant. In certain cases, a viewing test with expert test subjects can be performed, for example if a test should evaluate technologies with similar performance with respect to a particular artifact (e.g. loop filters or motion prediction). Depending on the setup of the test, the output could be a MOS, DMOS or a percentage of experts, who preferred one or another technology.</p>
<h1 id="rfc.section.3"><a href="#rfc.section.3">3.</a> <a href="#objective-metrics" id="objective-metrics">Objective Metrics</a></h1>
<p id="rfc.section.3.p.1">Objective metrics are used in place of subjective metrics for easy and repeatable experiments. Most objective metrics have been designed to correlate with subjective scores.</p>
<p id="rfc.section.3.p.2">The following descriptions give an overview of the operation of each of the metrics. Because implementation details can sometimes vary, the exact implementation is specified in C in the Daala tools repository <a href="#DAALA-GIT">[DAALA-GIT]</a>. Implementations of metrics must directly support the input&#8217;s resolution, bit depth, and sampling format.</p>
<p id="rfc.section.3.p.3">Unless otherwise specified, all of the metrics described below only apply to the luma plane, individually by frame. When applied to the video, the scores of each frame are averaged to create the final score.</p>
<p id="rfc.section.3.p.4">Codecs must output the same resolution, bit depth, and sampling format as the input.</p>
<h1 id="rfc.section.3.1"><a href="#rfc.section.3.1">3.1.</a> <a href="#overall-psnr" id="overall-psnr">Overall PSNR</a></h1>
<p id="rfc.section.3.1.p.1">PSNR is a traditional signal quality metric, measured in decibels. It is directly drived from mean square error (MSE), or its square root (RMSE). The formula used is:</p>
<p id="rfc.section.3.1.p.2">20 * log10 ( MAX / RMSE )</p>
<p id="rfc.section.3.1.p.3">or, equivalently:</p>
<p id="rfc.section.3.1.p.4">10 * log10 ( MAX^2 / MSE )</p>
<p id="rfc.section.3.1.p.5">where the error is computed over all the pixels in the video, which is the method used in the dump_psnr.c reference implementation.</p>
<p id="rfc.section.3.1.p.6">This metric may be applied to both the luma and chroma planes, with all planes reported separately.</p>
<h1 id="rfc.section.3.2"><a href="#rfc.section.3.2">3.2.</a> <a href="#frame-averaged-psnr" id="frame-averaged-psnr">Frame-averaged PSNR</a></h1>
<p id="rfc.section.3.2.p.1">PSNR can also be calculated per-frame, and then the values averaged together. This is reported in the same way as overall PSNR.</p>
<h1 id="rfc.section.3.3"><a href="#rfc.section.3.3">3.3.</a> <a href="#psnr-hvs-m" id="psnr-hvs-m">PSNR-HVS-M</a></h1>
<p id="rfc.section.3.3.p.1">The PSNR-HVS metric performs a DCT transform of 8x8 blocks of the image, weights the coefficients, and then calculates the PSNR of those coefficients. Several different sets of weights have been considered. <a href="#PSNRHVS">[PSNRHVS]</a> The weights used by the dump_pnsrhvs.c tool in the Daala repository have been found to be the best match to real MOS scores.</p>
<h1 id="rfc.section.3.4"><a href="#rfc.section.3.4">3.4.</a> <a href="#ssim" id="ssim">SSIM</a></h1>
<p id="rfc.section.3.4.p.1">SSIM (Structural Similarity Image Metric) is a still image quality metric introduced in 2004 <a href="#SSIM">[SSIM]</a>. It computes a score for each individual pixel, using a window of neighboring pixels. These scores can then be averaged to produce a global score for the entire image. The original paper produces scores ranging between 0 and 1.</p>
<p id="rfc.section.3.4.p.2">For the metric to appear more linear on BD-rate curves, the score is converted into a nonlinear decibel scale:</p>
<p id="rfc.section.3.4.p.3">-10 * log10 (1 - SSIM)</p>
<h1 id="rfc.section.3.5"><a href="#rfc.section.3.5">3.5.</a> <a href="#multi-scale-ssim" id="multi-scale-ssim">Multi-Scale SSIM</a></h1>
<p id="rfc.section.3.5.p.1">Multi-Scale SSIM is SSIM extended to multiple window sizes <a href="#MSSSIM">[MSSSIM]</a>.</p>
<h1 id="rfc.section.3.6"><a href="#rfc.section.3.6">3.6.</a> <a href="#fast-multi-scale-ssim" id="fast-multi-scale-ssim">Fast Multi-Scale SSIM</a></h1>
<p id="rfc.section.3.6.p.1">Fast MS-SSIM is a modified implementation of MS-SSIM which operates on a limited number of scales and with modified weights <a href="#FASTSSIM">[FASTSSIM]</a>. The final score is converted to decibels in the same manner as SSIM.</p>
<h1 id="rfc.section.3.7"><a href="#rfc.section.3.7">3.7.</a> <a href="#ciede2000" id="ciede2000">CIEDE2000</a></h1>
<p id="rfc.section.3.7.p.1">CIEDE2000 is a metric based on CIEDE color distances <a href="#CIEDE2000">[CIEDE2000]</a>. It generates a single score taking into account all three chroma planes. It does not take into consideration any structural similarity or other psychovisual effects.</p>
<h1 id="rfc.section.3.8"><a href="#rfc.section.3.8">3.8.</a> <a href="#vmaf" id="vmaf">VMAF</a></h1>
<p id="rfc.section.3.8.p.1">Video Multi-method Assessment Fusion (VMAF) is a full-reference perceptual video quality metric that aims to approximate human perception of video quality <a href="#VMAF">[VMAF]</a>. This metric is focused on quality degradation due compression and rescaling. VMAF estimates the perceived quality score by computing scores from multiple quality assessment algorithms, and fusing them using a support vector machine (SVM). Currently, three image fidelity metrics and one temporal signal have been chosen as features to the SVM, namely Anti-noise SNR (ANSNR), Detail Loss Measure (DLM), Visual Information Fidelity (VIF), and the mean co-located pixel difference of a frame with respect to the previous frame.</p>
<h1 id="rfc.section.4"><a href="#rfc.section.4">4.</a> <a href="#comparing-and-interpreting-results" id="comparing-and-interpreting-results">Comparing and Interpreting Results</a></h1>
<h1 id="rfc.section.4.1"><a href="#rfc.section.4.1">4.1.</a> <a href="#graphing" id="graphing">Graphing</a></h1>
<p id="rfc.section.4.1.p.1">When displayed on a graph, bitrate is shown on the X axis, and the quality metric is on the Y axis. For publication, the X axis should be linear. The Y axis metric should be plotted in decibels. If the quality metric does not natively report quality in decibels, it should be converted as described in the previous section.</p>
<h1 id="rfc.section.4.2"><a href="#rfc.section.4.2">4.2.</a> <a href="#bjontegaard" id="bjontegaard">Bjontegaard</a></h1>
<p id="rfc.section.4.2.p.1">The Bjontegaard rate difference, also known as BD-rate, allows the measurement of the bitrate reduction offered by a codec or codec feature, while maintaining the same quality as measured by objective metrics. The rate change is computed as the average percent difference in rate over a range of qualities. Metric score ranges are not static - they are calculated either from a range of bitrates of the reference codec, or from quantizers of a third, reference codec. Given a reference codec, test codec, and ranges, BD-rate values are calculated as follows:</p>
<p/>

<ul>
  <li>Rate/distortion points are calculated for the reference and test codec. There need to be enough points so that at least four points lie within the quality levels.</li>
  <li>The rates are converted into log-rates.</li>
  <li>A piecewise cubic hermite interpolating polynomial is fit to the points for each codec to produce functions of distortion in terms of log-rate.</li>
  <li>Metric score ranges are computed.  <ul><li>If using a bitrate range, metric score ranges are computed by converting the rate bounds into log-rate and then looking up scores of the reference codec using the interpolating polynomial.</li><li>If using a quantizer range, a third anchor codec is used to generate metric scores for the quantizer bounds. The anchor codec makes the range immune to quantizer changes.</li></ul></li>
  <li>The log-rate is numerically integrated over the metric range for each curve.</li>
  <li>The resulting integrated log-rates are converted back into linear rate, and then the percent difference is calculated from the reference to the test codec.</li>
</ul>
<h1 id="rfc.section.4.3"><a href="#rfc.section.4.3">4.3.</a> <a href="#ranges" id="ranges">Ranges</a></h1>
<p id="rfc.section.4.3.p.1">For all tests described in this document, quantizers of an anchor codec are used to determine the quality ranges. The anchor codec used for ranges is libvpx 1.5.0 run with VP9 and High Latency CQP settings. The quality range used is that achieved between cq-level 20 and 60.</p>
<h1 id="rfc.section.5"><a href="#rfc.section.5">5.</a> <a href="#test-sequences" id="test-sequences">Test Sequences</a></h1>
<h1 id="rfc.section.5.1"><a href="#rfc.section.5.1">5.1.</a> <a href="#sources" id="sources">Sources</a></h1>
<p id="rfc.section.5.1.p.1">Lossless test clips are preferred for most tests, because the structure of compression artifacts in already-compressed clips may introduce extra noise in the test results. However, a large amount of content on the internet needs to be recompressed at least once, so some sources of this nature are useful. The encoder should run at the same bit depth as the original source. In addition, metrics need to support operation at high bit depth. If one or more codecs in a comparison do not support high bit depth, sources need to be converted once before entering the encoder.</p>
<h1 id="rfc.section.5.2"><a href="#rfc.section.5.2">5.2.</a> <a href="#test-sets" id="test-sets">Test Sets</a></h1>
<p id="rfc.section.5.2.p.1">Sources are divided into several categories to test different scenarios the codec will be required to operate in. For easier comparison, all videos in each set should have the same color subsampling, same resolution, and same number of frames. In addition, all test videos must be publicly available for testing use, to allow for reproducibility of results. All current test sets are available for download <a href="#TESTSEQUENCES">[TESTSEQUENCES]</a>.</p>
<p/>

<ul>
  <li>Still images are useful when comparing intra coding performance. Xiph.org has four sets of lossless, one megapixel images that have been converted into YUV 4:2:0 format. There are four sets that can be used: <ul><li>subset1 (50 images)</li><li>subset2 (50 images)</li><li>subset3 (1000 images)</li><li>subset4 (1000 images)</li></ul></li>
  <li>video-hd-3, a set that consists of 1920x1080 clips from <a href="#DERFVIDEO">[DERFVIDEO]</a> (1500 frames total)</li>
  <li>vc-360p-1, a low quality video conferencing set (2700 frames total)</li>
  <li>vc-720p-1, a high quality video conferencing set (2750 frames total)</li>
  <li>netflix-4k-1, a cinematic 4K video test set (2280 frames total)</li>
  <li>netflix-2k-1, a 2K scaled version of netflix-4k-1 (2280 frames total)</li>
  <li>twitch-1, a game sequence set (2280 frames total)</li>
</ul>
<h1 id="rfc.section.5.3"><a href="#rfc.section.5.3">5.3.</a> <a href="#operating-points" id="operating-points">Operating Points</a></h1>
<p id="rfc.section.5.3.p.1">Four operating modes are defined. High latency is intended for on demand streaming, one-to-many live streaming, and stored video. Low latency is intended for videoconferencing and remote access. Both of these modes come in CQP and unconstrained variants. When testing still image sets, such as subset1, high latency CQP mode should be used.</p>
<h1 id="rfc.section.5.3.1"><a href="#rfc.section.5.3.1">5.3.1.</a> <a href="#common-settings" id="common-settings">Common settings</a></h1>
<p id="rfc.section.5.3.1.p.1">Encoders should be configured to their best settings when being compared against each other:</p>
<p/>

<ul>
  <li>av1: &#8211;codec=av1 &#8211;ivf &#8211;frame-parallel=0 &#8211;tile-columns=0 &#8211;cpu-used=0 &#8211;threads=1</li>
</ul>
<h1 id="rfc.section.5.3.2"><a href="#rfc.section.5.3.2">5.3.2.</a> <a href="#high-latency-cqp" id="high-latency-cqp">High Latency CQP</a></h1>
<p id="rfc.section.5.3.2.p.1">High Latency CQP is used for evaluating incremental changes to a codec. This method is well suited to compare codecs with similar coding tools. It allows codec features with intrinsic frame delay.</p>
<p/>

<ul>
  <li>daala: -v=x -b 2</li>
  <li>vp9: &#8211;end-usage=q &#8211;cq-level=x -lag-in-frames=25 -auto-alt-ref=2</li>
  <li>av1: &#8211;end-usage=q &#8211;cq-level=x -lag-in-frames=25 -auto-alt-ref=2</li>
</ul>
<h1 id="rfc.section.5.3.3"><a href="#rfc.section.5.3.3">5.3.3.</a> <a href="#low-latency-cqp" id="low-latency-cqp">Low Latency CQP</a></h1>
<p id="rfc.section.5.3.3.p.1">Low Latency CQP is used for evaluating incremental changes to a codec. This method is well suited to compare codecs with similar coding tools. It requires the codec to be set for zero intrinsic frame delay.</p>
<p/>

<ul>
  <li>daala: -v=x</li>
  <li>av1: &#8211;end-usage=q &#8211;cq-level=x -lag-in-frames=0</li>
</ul>
<h1 id="rfc.section.5.3.4"><a href="#rfc.section.5.3.4">5.3.4.</a> <a href="#unconstrained-high-latency" id="unconstrained-high-latency">Unconstrained High Latency</a></h1>
<p id="rfc.section.5.3.4.p.1">The encoder should be run at the best quality mode available, using the mode that will provide the best quality per bitrate (VBR or constant quality mode). Lookahead and/or two-pass are allowed, if supported. One parameter is provided to adjust bitrate, but the units are arbitrary.  Example configurations follow:</p>
<p/>

<ul>
  <li>x264: &#8211;crf=x</li>
  <li>x265: &#8211;crf=x</li>
  <li>daala: -v=x -b 2</li>
  <li>av1: &#8211;end-usage=q &#8211;cq-level=x -lag-in-frames=25 -auto-alt-ref=2</li>
</ul>
<h1 id="rfc.section.5.3.5"><a href="#rfc.section.5.3.5">5.3.5.</a> <a href="#unconstrained-low-latency" id="unconstrained-low-latency">Unconstrained Low Latency</a></h1>
<p id="rfc.section.5.3.5.p.1">The encoder should be run at the best quality mode available, using the mode that will provide the best quality per bitrate (VBR or constant quality mode), but no frame delay, buffering, or lookahead is allowed. One parameter is provided to adjust bitrate, but the units are arbitrary. Example configurations follow:</p>
<p/>

<ul>
  <li>x264: &#8211;crf-x &#8211;tune zerolatency</li>
  <li>x265: &#8211;crf=x &#8211;tune zerolatency</li>
  <li>daala: -v=x</li>
  <li>av1: &#8211;end-usage=q &#8211;cq-level=x -lag-in-frames=0</li>
</ul>
<h1 id="rfc.section.6"><a href="#rfc.section.6">6.</a> <a href="#automation" id="automation">Automation</a></h1>
<p id="rfc.section.6.p.1">Frequent objective comparisons are extremely beneficial while developing a new codec. Several tools exist in order to automate the process of objective comparisons. The Compare-Codecs tool allows BD-rate curves to be generated for a wide variety of codecs <a href="#COMPARECODECS">[COMPARECODECS]</a>. The Daala source repository contains a set of scripts that can be used to automate the various metrics used. In addition, these scripts can be run automatically utilizing distributed computers for fast results, with rd_tool <a href="#RD_TOOL">[RD_TOOL]</a>. This tool can be run via a web interface called AreWeCompressedYet <a href="#AWCY">[AWCY]</a>, or locally.</p>
<p id="rfc.section.6.p.2">Because of computational constraints, several levels of testing are specified.</p>
<h1 id="rfc.section.6.1"><a href="#rfc.section.6.1">6.1.</a> <a href="#regression-tests" id="regression-tests">Regression tests</a></h1>
<p id="rfc.section.6.1.p.1">Regression tests run on a small number of short sequences. The regression tests should include a number of various test conditions. The purpose of regression tests is to ensure bug fixes (and similar patches) do not negatively affect the performance. The anchor in regression tests is the previous revision of the codec in source control. Regression tests are run on the following sets, in both high and low latency CQP modes:</p>
<p/>

<ul>
  <li>vc-720p-1</li>
  <li>netflix-2k-1</li>
</ul>
<h1 id="rfc.section.6.2"><a href="#rfc.section.6.2">6.2.</a> <a href="#objective-performance-tests" id="objective-performance-tests">Objective performance tests</a></h1>
<p id="rfc.section.6.2.p.1">Changes that are expected to affect the quality of encode or bitstream should run an objective performance test. The performance tests should be run on a wider number of sequences. If the option for the objective performance test is chosen, wide range and full length simulations are run on the site and the results (including all the objective metrics) are generated. Objective performance tests are run on the following sets, in both high and low latency CQP modes:</p>
<p/>

<ul>
  <li>video-hd-3</li>
  <li>netflix-2k-1</li>
  <li>netflix-4k-1</li>
  <li>vc-720p-1</li>
  <li>vc-360p-1</li>
  <li>twitch-1</li>
</ul>
<h1 id="rfc.section.6.3"><a href="#rfc.section.6.3">6.3.</a> <a href="#periodic-tests" id="periodic-tests">Periodic tests</a></h1>
<p id="rfc.section.6.3.p.1">Periodic tests are run on a wide range of bitrates in order to gauge progress over time, as well as detect potential regressions missed by other tests.</p>
<h1 id="rfc.references"><a href="#rfc.references">7.</a> Informative References</h1>
<table>
  <tbody>
    <tr>
      <td class="reference">
        <b id="AWCY">[AWCY]</b>
      </td>
      <td class="top"><a>Xiph.Org</a>, "<a href="https://arewecompressedyet.com/">Are We Compressed Yet?</a>", 2016.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="BT500">[BT500]</b>
      </td>
      <td class="top"><a>ITU-R</a>, "<a href="https://www.itu.int/dms_pubrec/itu-r/rec/bt/R-REC-BT.500-13-201201-I!!PDF-E.pdf">Recommendation ITU-R BT.500-13</a>", 2012.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="CIEDE2000">[CIEDE2000]</b>
      </td>
      <td class="top"><a>Yang, Y.</a>, <a>Ming, J.</a> and <a>N. Yu</a>, "<a href="http://dx.doi.org/10.1155/2012/273723">Color Image Quality Assessment Based on CIEDE2000</a>", 2012.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="COMPARECODECS">[COMPARECODECS]</b>
      </td>
      <td class="top"><a>Alvestrand, H.</a>, "<a href="http://compare-codecs.appspot.com/">Compare Codecs</a>", 2015.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="DAALA-GIT">[DAALA-GIT]</b>
      </td>
      <td class="top"><a>Xiph.Org</a>, "<a href="http://git.xiph.org/?p=daala.git;a=summary">Daala Git Repository</a>", 2015.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="DERFVIDEO">[DERFVIDEO]</b>
      </td>
      <td class="top"><a>Terriberry, T.</a>, "<a href="https://media.xiph.org/video/derf/">Xiph.org Video Test Media</a>", n.d..</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="FASTSSIM">[FASTSSIM]</b>
      </td>
      <td class="top"><a>Chen, M.</a> and <a>A. Bovik</a>, "<a href="http://live.ece.utexas.edu/publications/2011/chen_rtip_2011.pdf">Fast structural similarity index algorithm</a>", 2010.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="L1100">[L1100]</b>
      </td>
      <td class="top"><a>Bossen, F.</a>, "<a href="http://phenix.int-evry.fr/jct/">Common test conditions and software reference configurations</a>", JCTVC L1100, 2013.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="MSSSIM">[MSSSIM]</b>
      </td>
      <td class="top"><a>Wang, Z.</a>, <a>Simoncelli, E.</a> and <a>A. Bovik</a>, "<a href="http://www.cns.nyu.edu/~zwang/files/papers/msssim.pdf">Multi-Scale Structural Similarity for Image Quality Assessment</a>", n.d..</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="PSNRHVS">[PSNRHVS]</b>
      </td>
      <td class="top"><a>Egiazarian, K.</a>, <a>Astola, J.</a>, <a>Ponomarenko, N.</a>, <a>Lukin, V.</a>, <a>Battisti, F.</a> and <a>M. Carli</a>, "<a>A New Full-Reference Quality Metrics Based on HVS</a>", 2002.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="RD_TOOL">[RD_TOOL]</b>
      </td>
      <td class="top"><a>Xiph.Org</a>, "<a href="https://github.com/tdaede/rd_tool">rd_tool</a>", 2016.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="SSIM">[SSIM]</b>
      </td>
      <td class="top"><a>Wang, Z.</a>, <a>Bovik, A.</a>, <a>Sheikh, H.</a> and <a>E. Simoncelli</a>, "<a href="http://www.cns.nyu.edu/pub/eero/wang03-reprint.pdf">Image Quality Assessment: From Error Visibility to Structural Similarity</a>", 2004.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="STEAM">[STEAM]</b>
      </td>
      <td class="top"><a>Valve Corporation</a>, "<a href="http://store.steampowered.com/hwsurvey">Steam Hardware &amp; Software Survey: June 2015</a>", June 2015.</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="TESTSEQUENCES">[TESTSEQUENCES]</b>
      </td>
      <td class="top"><a>Daede, T.</a>, "<a href="https://people.xiph.org/~tdaede/sets/">Test Sets</a>", n.d..</td>
    </tr>
    <tr>
      <td class="reference">
        <b id="VMAF">[VMAF]</b>
      </td>
      <td class="top"><a>Aaron, A.</a>, <a>Li, Z.</a>, <a>Manohara, M.</a>, <a>Lin, J.</a>, <a>Wu, E.</a> and <a>C. Kuo</a>, "<a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=7351097">Challenges in cloud based ingest and encoding for high quality streaming media</a>", 2015.</td>
    </tr>
  </tbody>
</table>
<h1 id="rfc.authors">
  <a href="#rfc.authors">Authors' Addresses</a>
</h1>
<div class="avoidbreak">
  <address class="vcard">
	<span class="vcardline">
	  <span class="fn">Thomas Daede</span> 
	  <span class="n hidden">
		<span class="family-name">Daede</span>
	  </span>
	</span>
	<span class="org vcardline">Mozilla</span>
	<span class="adr">
	  
	  <span class="vcardline">
		<span class="locality"></span> 
		<span class="region"></span>
		<span class="code"></span>
	  </span>
	  <span class="country-name vcardline"></span>
	</span>
	<span class="vcardline">EMail: <a href="mailto:tdaede@mozilla.com">tdaede@mozilla.com</a></span>

  </address>
</div><div class="avoidbreak">
  <address class="vcard">
	<span class="vcardline">
	  <span class="fn">Andrey Norkin</span> 
	  <span class="n hidden">
		<span class="family-name">Norkin</span>
	  </span>
	</span>
	<span class="org vcardline">Netflix</span>
	<span class="adr">
	  
	  <span class="vcardline">
		<span class="locality"></span> 
		<span class="region"></span>
		<span class="code"></span>
	  </span>
	  <span class="country-name vcardline"></span>
	</span>
	<span class="vcardline">EMail: <a href="mailto:anorkin@netflix.com">anorkin@netflix.com</a></span>

  </address>
</div><div class="avoidbreak">
  <address class="vcard">
	<span class="vcardline">
	  <span class="fn">Ilya Brailovskiy</span> 
	  <span class="n hidden">
		<span class="family-name">Brailovskiy</span>
	  </span>
	</span>
	<span class="org vcardline">Amazon Lab126</span>
	<span class="adr">
	  
	  <span class="vcardline">
		<span class="locality"></span> 
		<span class="region"></span>
		<span class="code"></span>
	  </span>
	  <span class="country-name vcardline"></span>
	</span>
	<span class="vcardline">EMail: <a href="mailto:brailovs@lab126.com">brailovs@lab126.com</a></span>

  </address>
</div>

</body>
</html>